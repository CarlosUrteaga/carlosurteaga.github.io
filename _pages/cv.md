---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

Carlos is a Ph.D. student  an currently is a Data Scientist and ML Engineer who has been involved in different sectors such as Financial, Education, Retail, and Telecommunication for more than nine years. He has played a crucial role as MLOps engineer, where he deployed pipelines for integration, training and prediction using different architecture approaches to follow up model performance. Carlos has a strong foundation in computer science and machine learning. In addition, he played as a research assistant for a leading University at Mexico in the development of AI algorithms for pattern recognition and robotics using computer vision.

Currently he works on Generative AI to standardize different LLMs model to have  only one  access  and  include RAGs.

Education
======
* Ph.D. student in Computer Science, UNADE, (expected 2026)
* Diplom in Applied Machine Learning, 2019
* M.S. in Computer Science, ITAM, 2017
* B.S. in Telematics Engineer, ITAM, 2015

Work experience
======
* From March 2019 until today: 
  * Data Scientist Sr III
    Currently working as staff augmentation for a Big Four  company.
    * Identified and evaluated emerging technologies for GenAi and MLops tools for potential implementation in Azure, focusing on reducing complexity.
    * Generated a Proof of Concept (POC) for WhisperAI for calls and meetings, demonstrating the extraction of summaries and action points.
    * Designed and coded a Retrieval Augmented Generation system within a private Azure instance, integrating summarization and semantic search functionalities.
    * Implemented a monitoring system for a machine learning (ML) infrastructure using Grafana and Prometheus, enabling the identification of bottlenecks and resource consumption across multiple models.
  * Data  Scientist Sr II
    * Propose and design MLOps task to track efficiency of the model, after this I lead MLops team to follow best practices to follow up AI models using MLFlow and ArgoFlow
    * Design a classification system with random forest for technical interview matchers with 90 % of accuracy.Tools used Python, sk-learn and flask.
    * Extract information from resumes using Natural Language Processing (NLP) and computer vision (CV), each skill repetition and appearance permit create an score
    * Generate a data flow to extract, import and evaluate a candidate to suggest a studio. Use ensemble models with KNN and random forest to resilient the data inconsistencies.
    * Designed a Talent Acquisition model aimed at matching interviewers and evaluators efficiently. Utilized Intelligent Scheduling techniques to analyze availability through calendar integration, accounting for time zones and language restrictions, resulting in time savings.
    * Proposed and designed an MLOps task to monitor and optimize the efficiency of the Talent Acquisition model, incorporating queue management for streamlined operations. Led an MLOps team in the implementation of industry best practices for AI model management, leveraging MLFlow and ArgoFlow for comprehensive tracking and optimization.
    * Designed a classification system employing random forest algorithms to match technical interviewers with candidates, achieving a remarkable accuracy rate of 90%. Employed Python, scikit-learn, and Flask for implementation.
    * Leveraged Natural Language Processing (NLP) and computer vision (CV) techniques to extract information from resumes. Developed algorithms to score each skill based on its repetition and appearance, enhancing candidate evaluation.
    * Engineered a data flow pipeline to extract, import, and evaluate candidate data for suggesting suitable studio placements. Employed ensemble models, including KNN and random forest, to mitigate data inconsistencies and enhance resilience in candidate evaluation processes.
  * Data  Scientist Sr I
    * Augmentation staff as Data Architect to migrate a retail catalog from legacy to snowflake, each retail has their own data description and the project was to concentrate this information into Snowflake for all latinoamerica countries with 250,000 business.
    * Develop a pipeline to extract, clean and substitute information according to industry product masters and select the features.
    * Deploy and connect APIs over Flask to connect different sources and complement the information.
    * Python and Dask workshop, show pros and cons of dask to use in the different projects. 
    * Implement a data pipeline to enhance the quality of data extraction using regular expression. The quality was improved by 80% when the data was incomplete. Tools used, pandas, sklearn, python and docker. 
    * Create an ETL to add information from different sources into the data lake, some supported formats were XML, JSON and CSV.
    * Identify the industry product master field to match with a regular expression.
    * Using a VM (virtual machine) with Compute Engine on GCP, configure a docker to have a productive environment to extract the current data.
    * Generate a demographic report from each PoS dynamically.
    * Develop an AI solution for face recognition and people counting using Deep learning using only a few pictures. The solution involves data augmentation, face recognition and identification, object tracking, those must bear over a web service with real-time streaming (video and text).The tools used were Python, TensorFlow, Keras and Flask.
    * Data driven discovery to minimize cost for the IT area, we proposed a cost optimization for mobile phone plans and a Dashboard to generate reports and have enough visibility to enable agile decision-making. 
    * Implemented a xgboost model in Python + Docker and some NLP to detect domestic violence.
    * Generation of profile risk using feature engineering in order to predict the recidivism for LATAM mainly in Brazil, Uruguay and Honduras.

* September 2018 to March 2019 : Head of Data Science
  * Developed ML model for churn and default with Python, SQL,H2O, and Flask
  * Architect and Build machine learning software products for our core from local computer to use and hybrid setup for big data (AWS).
  * Lead all aspects of ML automation including model training and development, feature selection and model tuning with DM-CRISP Implementation. 
  * Evaluated the performance of projects using propensity score. This allows us to evaluate the impact compared without it. Generation of dashboard using Tableau.
  * Perform and speed up the business as usual in SQL query and batch script. 
  * Propose ROI method with a genetic algorithm to identify the best option between risk for each loan

* May 2018: Data Scientist Sr.
  * Analyzed and cleaned IVR data to recognize temporality and types of request through Python, Hadoop and SQL. This focus marketing activity invites users to install the Graphic IVR. 
  * Crafted a dashboard using Tableau to evaluate machine learning models. Dashboards were used for the main board to take action to analyze marketing activities.
  * Redesign an IVR mobile application considers the user and client experience, this decreases the number of incoming calls to the IVR and the cost of the call center.
  * Evaluation of ML models for Upsell, Cross-sell and Churn through a dashboard
  
* Oct 2017: Information Security Sr. 
  * Data analyst for compliance and monthly report of computer status to report unauthorized behavior. 
  * Management of users at a national level to guarantee a follow of IT policies, this is accomplished using python and Machine Learning (Random Forest) to detect leaks in the process.
  * Report Awareness and status to KPMG US and UK before the global system could generate the reports.

* 2012: Research Assistant
  * Microsoft Research: 
o Analyze the effect of students' multitasking during a computer class and final score.
    * Acquired and consolidated weekly information generated along the semester.
    * Analyzed, cataloged, and prepared the information for data analysis using python; delivered with one month of anticipation.
    * Provided statistical reports; the results were used in the final analysis.
  * Federal Telecommunications Institute: 
    * Design a fiber network for the Federal Telecommunication Institutes to connect towns with less than 10,000 inhabitants in Mexico.
      * Proposed an architecture to transform geographic information systems (GIS) into vectors for mapping; this helped to make better decisions on the selected network.
      * Visualized the result in a map using GIS on the Internet; the maps were used to show the best distribution.
    * Audit the mobile network in Mexico to discover failures in the quality of the service for each radio station.
      * Designed and coded a mobile application to extract the relevant information of a cellular tower like Cell ID, local Signal Strength Indication (RSSI), etc.
      * Collaborated in the development of a Web server which analyzes the quality of service.
  * Department of Digital Systems: 
    * Deploy vision algorithm for self-driving cars using ROS and OpenCV.
    * Study human behavior in an ascending auction of the radio spectrum.
    * Fraud detection in spectrum auction by detecting unusual bids by analyzing historical binds using SQL.
    * Development of a middleman program to identify clusters by income and behavior of auctioneers. 
    * Coded an auction platform using Azure cloud service with VB.net and S
    * Develop a mobile solution to differentiate the Polaroid brand in:
      * Organize a team with five other people using Scrum
      * Modified the Android operating system to add homemade mobile applications.
      * Reviewed the user experience guide of the mobile app.

IT Manager                  Ago. 2010 â€“ Oct. 2017
Administration of laboratories used for academics. 
  * Provided software and configuration according to the class; improving resources using virtualization. 
  * Administration of Google Classroom and Active directory for students and lecturer.
  * Advanced user in Unix/Linux, Windows, Windows Server, and OSX 


Tools
======
* Python
  * Scikit Learn
  * Pandas
  * Tensorflow
  * Keras
  * OpenCV
  * Flask
  * Request
* ROS
* Arduino
* Docker
* SQL
* H2O
* Big Data
  * Hadoop
  * Spark
  * Hive

Publications
======
  <ul>{% for post in site.publications %}
    {% include archive-single-cv.html %}
  {% endfor %}</ul>
  
Talks
======
  <ul>{% for post in site.talks %}
    {% include archive-single-talk-cv.html %}
  {% endfor %}</ul>
  
Teaching
======
  <ul>{% for post in site.teaching %}
    {% include archive-single-cv.html %}
  {% endfor %}</ul>


Hobbies
======
* Cooking
* Playing guitar
* Running