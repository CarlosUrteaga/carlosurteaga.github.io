---
title: "Ask First, Test on Demand: A Deference-Gated Socratic Agent Design" 
date: 2025-10-03
url: /socratic-agent/
tags: ["AI Agents", "Large Language Model"]
author: ["J. Carlos Urteaga-Reyesvera"]
description: "This paper presents a Socratic Agent: a small, auditable tutoring model that foregrounds the learner’s reasoning rather than exposing the model’s chain-of-thought." 
summary: "This paper presents a Socratic Agent: a small, auditable tutoring model that foregrounds the learner’s using a loop Elicit → Structure → Test → Summarize." 
cover:
#    image: "/1s.png"
    alt: "Socratic"


---

<!-- + [Paper](/static/conielecomp2016_paper_44.pdf)
+ [Online appendix](/static/conielecomp2016_paper_44.pdf) -->

---

##### Abstract

This paper presents a Socratic Agent: a small, auditable tutoring model that foregrounds the learner’s reasoning rather than exposing the model’s chain-of-thought. To mitigate cognitive offloading risks from general-purpose LLMs, we target edge-capable Small Language Models adapted via lightweight fine-tuning for classroom use. The agent runs a compact loop—Elicit → Structure → Test → Summarize—modulated by a stance st ∈ {explore, verify} and a readiness score Rt that gates the disclosure of answers via a logit-bias–based deference mechanism. Dialogue is constrained to a small set of speech acts (ask, clarify, probe, challenge, summarize, verify). Evidence and metacognition are externalized into two artifacts: a Learner Reasoning Trace (claims, steps, evidence, counterexamples) and a metacognitive ledger (goals, assumptions, plans, criteria, confidence). Tool use follows an ask-first, teston-demand policy; curated tools (e.g., calculator, unit check, code runner, rubric check) are executed solely to evaluate learner hypotheses without revealing solutions. We outline an evaluation plan across numeric and units tasks, diagram reading, rubric-graded responses, and conceptual probes, with outcomes measures for learning and retention, metacognitive coverage, trace quality, deference compliance, and cost and latency, and we discuss limitations, ablations, and a practical path from design to evidence. This work is offered as a design that articulates an auditable tutoring architecture and a concrete evaluation plan to guide future empirical validation.

---

<!-- ##### Citation

Urteaga-Reyesvera, J. C., & Possani-Espinosa, A. (2016, February). Scorpions: Classification of poisonous species using shape features. In 2016 International Conference on Electronics, Communications and Computers (CONIELECOMP) (pp. 125-129). IEEE.


```latex
@inproceedings{urteaga2016scorpions,
  title={Scorpions: Classification of poisonous species using shape features},
  author={Urteaga-Reyesvera, J Carlos and Possani-Espinosa, Andre},
  booktitle={2016 International Conference on Electronics, Communications and Computers (CONIELECOMP)},
  pages={125--129},
  year={2016},
  organization={IEEE}
}
```
 -->
